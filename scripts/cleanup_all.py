#!/usr/bin/env python3
"""
å®Œå…¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã‚·ãƒŠãƒªã‚ªé–¢é€£ã®ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¨ãƒ­ã‚°ã‚’å‰Šé™¤ã—ã¾ã™ï¼š
- ã‚·ãƒŠãƒªã‚ªJSONï¼ˆnatural, pegasus, abstract, logical, execution, parametersï¼‰
- Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆ
- å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.mp4ï¼‰
- RRDãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.rrdï¼‰
- Embeddingãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.json, .npyï¼‰
- ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«
- FiftyOneãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå†…ã®å¯¾å¿œã™ã‚‹sample
- Sandboxãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
"""

import argparse
import shutil
import json
from pathlib import Path
from typing import Dict, List, Set, Tuple


def get_file_size(file_path: Path) -> int:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’å–å¾—ï¼ˆãƒã‚¤ãƒˆï¼‰"""
    try:
        return file_path.stat().st_size
    except:
        return 0


def format_size(size_bytes: int) -> str:
    """ãƒã‚¤ãƒˆã‚’äººé–“ãŒèª­ã¿ã‚„ã™ã„å½¢å¼ã«å¤‰æ›"""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if size_bytes < 1024.0:
            return f"{size_bytes:.1f}{unit}"
        size_bytes /= 1024.0
    return f"{size_bytes:.1f}TB"


def extract_scenario_ids(files: Dict[str, List[Path]]) -> Set[Tuple[str, str]]:
    """
    å‰Šé™¤å¯¾è±¡ã®execution_*.jsonã‹ã‚‰(logical_uuid, parameter_uuid)ã®ãƒšã‚¢ã‚’æŠ½å‡º
    FiftyOneã‹ã‚‰å‰Šé™¤ã™ã‚‹sampleã‚’ç‰¹å®šã™ã‚‹ãŸã‚ã«ä½¿ç”¨
    """
    scenario_ids = set()

    for execution_file in files.get("scenarios", []):
        if execution_file.name.startswith("execution_"):
            try:
                with open(execution_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    logical_uuid = data.get("logical_uuid")
                    parameter_uuid = data.get("parameter_uuid")
                    if logical_uuid and parameter_uuid:
                        scenario_ids.add((logical_uuid, parameter_uuid))
            except Exception as e:
                print(f"âš ï¸  execution_*.jsonèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {execution_file.name} - {e}")

    return scenario_ids


def collect_files(base_dir: Path, include_sandbox: bool = False) -> Dict[str, List[Path]]:
    """å‰Šé™¤å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†"""
    files = {
        "scenarios": [],
        "python": [],
        "videos": [],
        "rerun": [],
        "embeddings": [],
        "logs": [],
        "params": [],
    }

    scenarios_dir = base_dir / "data" / "scenarios"
    python_dir = base_dir / "scenarios"
    videos_dir = base_dir / "data" / "videos"
    rerun_dir = base_dir / "data" / "rerun"
    embeddings_dir = base_dir / "data" / "embeddings"
    logs_dir = base_dir / "logs"

    # ã‚·ãƒŠãƒªã‚ªJSONï¼ˆnatural, pegasus, abstract, logical, executionï¼‰
    if scenarios_dir.exists():
        files["scenarios"].extend(scenarios_dir.glob("natural_*.json"))
        files["scenarios"].extend(scenarios_dir.glob("pegasus_*.json"))
        files["scenarios"].extend(scenarios_dir.glob("abstract_*.json"))
        files["scenarios"].extend(scenarios_dir.glob("logical_*.json"))
        files["scenarios"].extend(scenarios_dir.glob("execution_*.json"))

    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿JSON
    if scenarios_dir.exists():
        files["params"].extend(scenarios_dir.glob("params_*.json"))
        files["params"].extend(scenarios_dir.glob("logical_*_parameters.json"))

    # Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆ
    if python_dir.exists():
        files["python"].extend(python_dir.glob("*.py"))
        # examples/ä»¥ä¸‹ã¯é™¤å¤–
        files["python"] = [f for f in files["python"] if "examples" not in str(f)]

    # å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«
    if videos_dir.exists():
        files["videos"].extend(videos_dir.glob("*.mp4"))

    # RRDãƒ•ã‚¡ã‚¤ãƒ«
    if rerun_dir.exists():
        files["rerun"].extend(rerun_dir.glob("*.rrd"))

    # Embeddingãƒ•ã‚¡ã‚¤ãƒ«
    if embeddings_dir.exists():
        files["embeddings"].extend(embeddings_dir.glob("*.json"))
        files["embeddings"].extend(embeddings_dir.glob("*.npy"))

    # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«
    if logs_dir.exists():
        files["logs"].extend(logs_dir.glob("*.log"))

    # Sandboxãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    if include_sandbox:
        sandbox_workspace = base_dir / "sandbox" / "workspace"
        if sandbox_workspace.exists():
            # UUIDãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤
            for uuid_dir in sandbox_workspace.iterdir():
                if uuid_dir.is_dir() and uuid_dir.name != ".gitkeep":
                    files.setdefault("sandbox", []).append(uuid_dir)

    return files


def delete_files(files: Dict[str, List[Path]], dry_run: bool = True) -> None:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤"""
    total_files = sum(len(file_list) for file_list in files.values())
    total_size = 0

    print("\n=== å‰Šé™¤å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ« ===\n")

    for category, file_list in files.items():
        if not file_list:
            continue

        category_size = sum(get_file_size(f) for f in file_list)
        total_size += category_size

        print(f"ã€{category}ã€‘")
        for file_path in file_list:
            size_str = format_size(get_file_size(file_path))
            print(f"  - {file_path} ({size_str})")
        print(f"  å°è¨ˆ: {format_size(category_size)}\n")

    print(f"=== åˆè¨ˆ: {total_files}ãƒ•ã‚¡ã‚¤ãƒ«, {format_size(total_size)} ===\n")

    if dry_run:
        print("â„¹ï¸  ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ãƒ¢ãƒ¼ãƒ‰: ãƒ•ã‚¡ã‚¤ãƒ«ã¯å‰Šé™¤ã•ã‚Œã¾ã›ã‚“")
        print("   å®Ÿéš›ã«å‰Šé™¤ã™ã‚‹ã«ã¯ --force ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„")
        return

    # å®Ÿéš›ã«å‰Šé™¤
    deleted_count = 0
    for file_list in files.values():
        for file_path in file_list:
            try:
                if file_path.is_dir():
                    shutil.rmtree(file_path)
                else:
                    file_path.unlink()
                print(f"âœ“ å‰Šé™¤: {file_path}")
                deleted_count += 1
            except Exception as e:
                print(f"âœ— ã‚¨ãƒ©ãƒ¼: {file_path} - {e}")

    print(f"\nâœ“ {deleted_count}ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")


def cleanup_fiftyone_samples(
    scenario_ids: Set[Tuple[str, str]],
    dataset_name: str = "carla-scenarios",
    dry_run: bool = True
) -> None:
    """
    FiftyOneãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰å‰Šé™¤ã•ã‚ŒãŸã‚·ãƒŠãƒªã‚ªã«å¯¾å¿œã™ã‚‹sampleã‚’å‰Šé™¤

    Args:
        scenario_ids: (logical_uuid, parameter_uuid)ã®ã‚»ãƒƒãƒˆ
        dataset_name: FiftyOneãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå
        dry_run: Trueã®å ´åˆã€å‰Šé™¤ã—ãªã„
    """
    if not scenario_ids:
        print("\nã€FiftyOne Samplesã€‘")
        print("  - å‰Šé™¤å¯¾è±¡ã®ã‚·ãƒŠãƒªã‚ªIDãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰")
        return

    try:
        import fiftyone as fo

        if not fo.dataset_exists(dataset_name):
            print(f"\nã€FiftyOne Samplesã€‘")
            print(f"  - ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ '{dataset_name}' ã¯å­˜åœ¨ã—ã¾ã›ã‚“")
            return

        dataset = fo.load_dataset(dataset_name)
        deleted_count = 0
        samples_to_delete = []

        print(f"\nã€FiftyOne Samplesã€‘")
        print(f"  ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {dataset_name}")
        print(f"  å‰Šé™¤å¯¾è±¡ã‚·ãƒŠãƒªã‚ªæ•°: {len(scenario_ids)}")

        # å‰Šé™¤å¯¾è±¡ã®sampleã‚’æ¤œç´¢
        for logical_uuid, parameter_uuid in scenario_ids:
            # ãƒ•ã‚¡ã‚¤ãƒ«åãƒ‘ã‚¿ãƒ¼ãƒ³: {logical_uuid}_{parameter_uuid}.mp4
            video_filename = f"{logical_uuid}_{parameter_uuid}.mp4"

            # FiftyOneã‹ã‚‰sampleã‚’æ¤œç´¢ï¼ˆfilepathéƒ¨åˆ†ä¸€è‡´ï¼‰
            view = dataset.match({"filepath": {"$regex": video_filename}})

            for sample in view:
                samples_to_delete.append(sample.id)
                print(f"  - å‰Šé™¤äºˆå®š: {Path(sample.filepath).name}")

        if not samples_to_delete:
            print(f"  - å‰Šé™¤å¯¾è±¡ã®sampleãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return

        if not dry_run:
            # å®Ÿéš›ã«å‰Šé™¤
            dataset.delete_samples(samples_to_delete)
            deleted_count = len(samples_to_delete)
            print(f"\nâœ“ FiftyOneã‹ã‚‰{deleted_count}ä»¶ã®sampleã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
        else:
            print(f"\n  ï¼ˆ{len(samples_to_delete)}ä»¶ã®sampleã‚’å‰Šé™¤äºˆå®šï¼‰")

    except ImportError:
        print("\nâš ï¸  FiftyOneãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰")
    except Exception as e:
        print(f"\nâœ— FiftyOne sampleå‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()


def delete_fiftyone_dataset(dataset_name: str = "carla-scenarios", dry_run: bool = True) -> None:
    """FiftyOneãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã‚’å‰Šé™¤"""
    try:
        import fiftyone as fo

        if fo.dataset_exists(dataset_name):
            print(f"\nã€FiftyOne Datasetï¼ˆå…¨ä½“å‰Šé™¤ï¼‰ã€‘")
            print(f"  - {dataset_name}")

            if not dry_run:
                fo.delete_dataset(dataset_name)
                print(f"âœ“ FiftyOneãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå‰Šé™¤: {dataset_name}")
            else:
                print(f"  ï¼ˆå‰Šé™¤äºˆå®šï¼‰")
        else:
            print(f"\nã€FiftyOne Datasetã€‘")
            print(f"  - ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ '{dataset_name}' ã¯å­˜åœ¨ã—ã¾ã›ã‚“")

    except ImportError:
        print("\nâš ï¸  FiftyOneãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰")
    except Exception as e:
        print(f"\nâœ— FiftyOneãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")


def main():
    parser = argparse.ArgumentParser(
        description="ã‚·ãƒŠãƒªã‚ªé–¢é€£ã®ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¨ãƒ­ã‚°ã‚’å‰Šé™¤"
    )
    parser.add_argument(
        "--force",
        action="store_true",
        help="å®Ÿéš›ã«å‰Šé™¤ã‚’å®Ÿè¡Œï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ï¼‰"
    )
    parser.add_argument(
        "--include-sandbox",
        action="store_true",
        help="Sandboxãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ã‚‚å‰Šé™¤"
    )
    parser.add_argument(
        "--fiftyone-dataset",
        default="carla-scenarios",
        help="FiftyOneãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: carla-scenariosï¼‰"
    )
    parser.add_argument(
        "--no-fiftyone",
        action="store_true",
        help="FiftyOneé–¢é€£ã®å‰Šé™¤ã‚’ã‚¹ã‚­ãƒƒãƒ—"
    )
    parser.add_argument(
        "--delete-entire-dataset",
        action="store_true",
        help="ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã‚’å‰Šé™¤ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯å€‹åˆ¥sampleå‰Šé™¤ï¼‰"
    )

    args = parser.parse_args()

    base_dir = Path.cwd()

    print("=" * 60)
    if args.force:
        print("ğŸ—‘ï¸  å®Œå…¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆå®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ï¼‰")
    else:
        print("ğŸ” å®Œå…¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ï¼‰")
    print("=" * 60)

    # ãƒ•ã‚¡ã‚¤ãƒ«åé›†
    print("\nãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ä¸­...")
    files = collect_files(base_dir, include_sandbox=args.include_sandbox)

    # ã‚·ãƒŠãƒªã‚ªIDã‚’æŠ½å‡ºï¼ˆFiftyOneå‰Šé™¤ç”¨ï¼‰
    scenario_ids = extract_scenario_ids(files)
    if scenario_ids:
        print(f"  æŠ½å‡ºã•ã‚ŒãŸã‚·ãƒŠãƒªã‚ªID: {len(scenario_ids)}ä»¶")

    # ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
    delete_files(files, dry_run=not args.force)

    # FiftyOneå‡¦ç†
    if not args.no_fiftyone:
        if args.delete_entire_dataset:
            # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã‚’å‰Šé™¤
            delete_fiftyone_dataset(args.fiftyone_dataset, dry_run=not args.force)
        else:
            # å€‹åˆ¥sampleã‚’å‰Šé™¤
            cleanup_fiftyone_samples(
                scenario_ids,
                dataset_name=args.fiftyone_dataset,
                dry_run=not args.force
            )

    if not args.force:
        print("\nğŸ’¡ å®Ÿéš›ã«å‰Šé™¤ã™ã‚‹ã«ã¯:")
        print("   uv run python scripts/cleanup_all.py --force")


if __name__ == "__main__":
    main()
